folders {
    generatedPlanAndTaskFolderPath = "src/test/resources/sample/e2e/generated"
    planFilePath = "sample/e2e/plan/e2e_test_plan.yaml"
    taskFolderPath = "sample/e2e/task"
    validationFolderPath = "src/test/resources/sample/e2e/validation"
    recordTrackingFolderPath = "src/test/resources/sample/e2e/data/recordTracking"
    recordTrackingForValidationFolderPath = "/tmp/data/validation/recordTracking"
    generatedReportsFolderPath = "src/test/resources/sample/e2e/report/html"
}

flags {
    enableCount = true
    enableGenerateData = true
    enableGeneratePlanAndTasks = true
    enableRecordTracking = true
    enableDeleteGeneratedRecords = false
}

metadata {
    numRecordsFromDataSource = 10000
    numRecordsForAnalysis = 10000
    oneOfDistinctCountVsCountThreshold = 0.1
}

generation {}
validation {}
alert {}

runtime{
    master = "local[*]"
    config {
        "spark.sql.cbo.enabled" = "true"
        "spark.sql.adaptive.enabled" = "true"
        "spark.sql.cbo.planStats.enabled" = "true"
        "spark.sql.legacy.allowUntypedScalaUDF" = "true"
        "spark.sql.statistics.histogram.enabled" = "true"
        "spark.sql.shuffle.partitions" = "10"
        "spark.sql.catalog.postgres": "",
        "spark.sql.catalog.cassandra": "com.datastax.spark.connector.datasource.CassandraCatalog",
        "spark.sql.catalog.iceberg": "org.apache.iceberg.spark.SparkCatalog",
        "spark.sql.catalog.iceberg.type": "hadoop",
        "spark.hadoop.fs.s3a.directory.marker.retention": "keep",
        "spark.hadoop.fs.s3a.bucket.all.committer.magic.enabled": "true",
        "spark.hadoop.fs.hdfs.impl": "org.apache.hadoop.hdfs.DistributedFileSystem",
        "spark.hadoop.fs.file.impl": "com.globalmentor.apache.hadoop.fs.BareLocalFileSystem",
        "spark.sql.extensions": "io.delta.sql.DeltaSparkSessionExtension,org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions"
    }
}

json {
    json_datasource {
    }
}

csv {
    csv_datasource {
    }
}